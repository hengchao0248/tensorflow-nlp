{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformer_export.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tJIH75zLJTC3","colab_type":"code","colab":{}},"source":["\"\"\"\n","We use following lines because we are running on Google Colab\n","If you are running notebook on a local computer, you don't need this cell\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese/main')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4I905bZJvrLt","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","!pip install texar"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5Jap8hmJYhu","colab_type":"code","outputId":"2d03e23a-cb34-49de-d505-6f9e4b1e811e","executionInfo":{"status":"ok","timestamp":1576026596656,"user_tz":-480,"elapsed":261630,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import tensorflow as tf\n","import texar.tf as tx\n","import numpy as np\n","import copy\n","\n","from texar.tf.modules import TransformerEncoder, TransformerDecoder\n","\n","print(\"TensorFlow Version\", tf.__version__)\n","print('GPU Enabled:', tf.test.is_gpu_available())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["TensorFlow Version 1.15.0\n","GPU Enabled: False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f3d8hOgMJ1IR","colab_type":"code","colab":{}},"source":["def forward(features, labels, mode):\n","    if isinstance(features, dict):\n","      words = features['words']\n","    else:\n","      words = features\n","    \n","    words_len = tf.count_nonzero(words, 1, dtype=tf.int32)\n","    \n","    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","    batch_sz = tf.shape(words)[0]\n","    \n","  \n","    with tf.variable_scope('Embedding'):\n","        embedding = tf.Variable(np.load('../vocab/char.npy'),\n","                                dtype=tf.float32,\n","                                name='fasttext_vectors')\n","        embedding = tf.concat([tf.zeros(shape=[1, params['embed_dim']]), embedding[1:, :]], axis=0)\n","        x = tf.nn.embedding_lookup(embedding, words)\n","        pos_embedder = tx.modules.SinusoidsPositionEmbedder(\n","            position_size = 2*params['max_len'],\n","            hparams = config_model.position_embedder_hparams)\n","        x = (x * config_model.hidden_dim ** 0.5) + pos_embedder(sequence_length=words_len)\n","\n","\n","    with tf.variable_scope('Encoder'):\n","        encoder = TransformerEncoder(hparams=config_model.encoder)\n","        enc_out = encoder(inputs=x, sequence_length=words_len)\n","    \n","    \n","    with tf.variable_scope('Decoder'):\n","        decoder = TransformerDecoder(vocab_size=len(params['char2idx'])+1,\n","                                     output_layer=tf.transpose(embedding, (1, 0)),\n","                                     hparams=config_model.decoder)\n","        \n","        start_tokens = tf.fill([batch_sz], 1)\n","\n","        def _embedding_fn(x, y):\n","            x_w_embed = tf.nn.embedding_lookup(embedding, x)\n","            y_p_embed = pos_embedder(y)\n","            return x_w_embed * config_model.hidden_dim ** 0.5 + y_p_embed\n","\n","        predictions = decoder(\n","            memory=enc_out,\n","            memory_sequence_length=words_len,\n","            beam_width=params['beam_width'],\n","            length_penalty=params['length_penalty'],\n","            start_tokens=start_tokens,\n","            end_token=2,\n","            embedding=_embedding_fn,\n","            max_decoding_length=params['max_len'],\n","            mode=tf.estimator.ModeKeys.PREDICT)\n","        \n","        return predictions['sample_id'][:, :, :params['top_k']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ndq26dhcJ_X6","colab_type":"code","colab":{}},"source":["def model_fn(features, labels, mode, params):\n","    logits_or_ids = forward(features, labels, mode)\n","    \n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode, predictions=logits_or_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUtptCqjKCBc","colab_type":"code","colab":{}},"source":["class config_model:\n","    hidden_dim = 300\n","    num_heads = 8\n","    dropout_rate = .2\n","    num_blocks = 6\n","\n","    position_embedder_hparams = {\n","        'dim': hidden_dim\n","    }\n","\n","    encoder = {\n","        'dim': hidden_dim,\n","        'embedding_dropout': dropout_rate,\n","        'residual_dropout': dropout_rate,\n","        'num_blocks': num_blocks,\n","        'initializer': {\n","            'type': 'variance_scaling_initializer',\n","            'kwargs': {\n","                'scale': 1.0,\n","                'mode': 'fan_avg',\n","                'distribution': 'uniform',\n","            },\n","        },\n","        'multihead_attention': {\n","            'dropout_rate': dropout_rate,\n","            'num_heads': num_heads,\n","            'output_dim': hidden_dim,\n","            'use_bias': True,\n","        },\n","        'poswise_feedforward': {\n","          'name': 'fnn',\n","          'layers': [\n","              {\n","                  'type': 'Dense',\n","                  'kwargs': {\n","                      'name': 'conv1',\n","                      'units': hidden_dim * 2,\n","                      'activation': 'gelu',\n","                      'use_bias': True,\n","                  },\n","              },\n","              {\n","                  'type': 'Dropout',\n","                  'kwargs': {\n","                      'rate': dropout_rate,\n","                  }\n","              },\n","              {\n","                  'type': 'Dense',\n","                  'kwargs': {\n","                      'name': 'conv2',\n","                      'units': hidden_dim,\n","                      'use_bias': True,\n","                  }\n","              }\n","          ],\n","        },\n","    }\n","\n","    decoder = copy.deepcopy(encoder)\n","    decoder['output_layer_bias'] = True\n","\n","\n","params = {\n","    'model_dir': '../model/transformer',\n","    'export_dir': '../model/transformer_export',\n","    'vocab_path': '../vocab/char.txt',\n","    'max_len': 15,\n","    'embed_dim': config_model.hidden_dim,\n","    'beam_width': 5,\n","    'top_k': 3,\n","    'length_penalty': .6,\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yA9cnR_cKFmD","colab_type":"code","colab":{}},"source":["def serving_input_receiver_fn():\n","    words = tf.placeholder(tf.int32, [None, None], 'words')\n","    \n","    features = {'words': words}\n","    receiver_tensors = features\n","    \n","    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NpHXFOdPMSmw","colab_type":"code","colab":{}},"source":["def get_vocab(f_path):\n","  word2idx = {}\n","  with open(f_path) as f:\n","    for i, line in enumerate(f):\n","      line = line.rstrip('\\n')\n","      word2idx[line] = i\n","  return word2idx"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQCSv49ZMPPn","colab_type":"code","colab":{}},"source":["params['char2idx'] = get_vocab(params['vocab_path'])\n","params['idx2char'] = {idx: char for char, idx in params['char2idx'].items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JaOquMcTLB_D","colab_type":"code","outputId":"3867bb34-ef27-4315-e377-cf153f0aa75c","executionInfo":{"status":"ok","timestamp":1576026614103,"user_tz":-480,"elapsed":279044,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCTG5IRIY_e34bmy4oR2FFkJW6Hlvr9nFF4nYPVlA=s64","userId":"01997730851420384589"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["estimator = tf.estimator.Estimator(model_fn, params['model_dir'])\n","estimator.export_saved_model(params['export_dir'], serving_input_receiver_fn)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'../model/transformer_export/1576026596'"]},"metadata":{"tags":[]},"execution_count":10}]}]}